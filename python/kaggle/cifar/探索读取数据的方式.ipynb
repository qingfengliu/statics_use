{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8a591f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "625e6b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, file_path=[], crop_size_img=None, crop_size_label=None):\n",
    "        \"\"\"para:\n",
    "            file_path(list): 数据和标签路径,列表元素第一个为图片路径，第二个为标签路径\n",
    "        \"\"\"\n",
    "        # 1 正确读入图片和标签路径\n",
    "        if len(file_path) != 2:\n",
    "            raise ValueError(\"同时需要图片和标签文件夹的路径，图片路径在前\")\n",
    "        self.img_path = file_path[0]\n",
    "        self.label_path = file_path[1]\n",
    "        # 2 从路径中取出图片和标签数据的文件名保持到两个列表当中（程序中的数据来源）\n",
    "        self.imgs = self.read_file(self.img_path)\n",
    "        labels=pd.read_csv(file_path[1])\n",
    "        self.labels = labels['y'].to_list()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # 从文件名中读取数据（图片和标签都是png格式的图像数据）\n",
    "        img = self.imgs[index]\n",
    "        img = Image.open(img)\n",
    "        label = self.labels[index]\n",
    "        img = self.img_transform(img, label)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def read_file(self, path):\n",
    "        \"\"\"从文件夹中读取数据\"\"\"\n",
    "        files_list = os.listdir(path)\n",
    "        \n",
    "        file_path_list = {int(re.search(r'(?<=train\\\\)[0-9]+',os.path.join(path, img)).group(0)):os.path.join(path, img) for img in files_list}\n",
    "        return file_path_list\n",
    "\n",
    "    def img_transform(self, img, label):\n",
    "        \"\"\"对图片和标签做一些数值处理\"\"\"\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "        img = transform(img)\n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6058936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset=CIFAR10Dataset([r'D:\\书籍资料整理\\kaggle\\cifar-10\\train',r'D:\\书籍资料整理\\kaggle\\cifar-10\\label.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92258fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataloader = DataLoader(tensor_dataset,   # 封装的对象\n",
    "                               batch_size=2,     # 输出的batchsize\n",
    "                               shuffle=True,     # 随机输出\n",
    "                               num_workers=0)    # 只有1个进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aeb6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6784, 0.6667, 0.6627,  ..., 0.6627, 0.6627, 0.6549],\n",
      "          [0.6588, 0.6471, 0.6431,  ..., 0.6353, 0.6353, 0.6353],\n",
      "          [0.6431, 0.6353, 0.6353,  ..., 0.6275, 0.6275, 0.6275],\n",
      "          ...,\n",
      "          [0.9333, 0.9176, 0.9176,  ..., 0.9137, 0.9137, 0.9216],\n",
      "          [0.9333, 0.9098, 0.9137,  ..., 0.9098, 0.9176, 0.9176],\n",
      "          [0.9294, 0.9098, 0.9059,  ..., 0.9059, 0.9176, 0.9176]],\n",
      "\n",
      "         [[0.7020, 0.6902, 0.6863,  ..., 0.6863, 0.6863, 0.6784],\n",
      "          [0.6824, 0.6667, 0.6667,  ..., 0.6588, 0.6588, 0.6588],\n",
      "          [0.6667, 0.6588, 0.6588,  ..., 0.6510, 0.6510, 0.6510],\n",
      "          ...,\n",
      "          [0.8588, 0.8431, 0.8471,  ..., 0.8314, 0.8314, 0.8392],\n",
      "          [0.8549, 0.8353, 0.8392,  ..., 0.8275, 0.8353, 0.8353],\n",
      "          [0.8510, 0.8353, 0.8314,  ..., 0.8235, 0.8353, 0.8353]],\n",
      "\n",
      "         [[0.7569, 0.7451, 0.7412,  ..., 0.7412, 0.7412, 0.7373],\n",
      "          [0.7373, 0.7216, 0.7216,  ..., 0.7137, 0.7137, 0.7137],\n",
      "          [0.7255, 0.7137, 0.7137,  ..., 0.7059, 0.7059, 0.7059],\n",
      "          ...,\n",
      "          [0.8824, 0.8667, 0.8706,  ..., 0.8588, 0.8588, 0.8667],\n",
      "          [0.8784, 0.8588, 0.8627,  ..., 0.8549, 0.8627, 0.8627],\n",
      "          [0.8784, 0.8588, 0.8549,  ..., 0.8510, 0.8627, 0.8627]]],\n",
      "\n",
      "\n",
      "        [[[0.9059, 0.8902, 0.8824,  ..., 0.9647, 0.9569, 0.9804],\n",
      "          [0.8941, 0.8902, 0.8510,  ..., 0.9608, 0.9490, 0.9725],\n",
      "          [0.8902, 0.8745, 0.8667,  ..., 0.9608, 0.9529, 0.9725],\n",
      "          ...,\n",
      "          [0.7216, 0.7373, 0.7725,  ..., 0.8549, 0.8549, 0.8667],\n",
      "          [0.7255, 0.7569, 0.7686,  ..., 0.8118, 0.8235, 0.8314],\n",
      "          [0.7373, 0.7569, 0.7569,  ..., 0.7843, 0.8000, 0.7961]],\n",
      "\n",
      "         [[0.8549, 0.8706, 0.8510,  ..., 0.9725, 0.9647, 0.9882],\n",
      "          [0.8745, 0.8824, 0.8353,  ..., 0.9686, 0.9569, 0.9804],\n",
      "          [0.8941, 0.8784, 0.8706,  ..., 0.9686, 0.9608, 0.9804],\n",
      "          ...,\n",
      "          [0.6902, 0.6941, 0.7490,  ..., 0.8392, 0.8471, 0.8667],\n",
      "          [0.6980, 0.7176, 0.7529,  ..., 0.8000, 0.8157, 0.8235],\n",
      "          [0.7059, 0.7176, 0.7373,  ..., 0.7804, 0.7961, 0.7843]],\n",
      "\n",
      "         [[0.7490, 0.7882, 0.7608,  ..., 0.9529, 0.9451, 0.9725],\n",
      "          [0.8000, 0.8078, 0.7451,  ..., 0.9490, 0.9373, 0.9686],\n",
      "          [0.8314, 0.8118, 0.7843,  ..., 0.9490, 0.9412, 0.9686],\n",
      "          ...,\n",
      "          [0.5490, 0.5608, 0.6353,  ..., 0.7569, 0.7725, 0.7882],\n",
      "          [0.5686, 0.5882, 0.6314,  ..., 0.6863, 0.7137, 0.7333],\n",
      "          [0.5725, 0.5804, 0.6078,  ..., 0.6902, 0.7176, 0.6941]]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a54b432d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 96])\n",
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 2)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29372/2625058236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                             num_workers=2))\n\u001b[0;32m     18\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_fashion_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29372/2625058236.py\u001b[0m in \u001b[0;36mload_data_fashion_mnist\u001b[1;34m(batch_size, resize)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n\u001b[0m\u001b[0;32m     15\u001b[0m                             num_workers=2),\n\u001b[0;32m     16\u001b[0m             data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None):  # @save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"D:/书籍资料整理/torch_data\", train=True, transform=trans, download=True)\n",
    "    print(mnist_train[2][0].shape)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"D:/书籍资料整理/torch_data\", train=False, transform=trans, download=True)\n",
    "    \n",
    "    print(mnist_test[1])\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))\n",
    "lr, num_epochs, batch_size = 0.05, 10, 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用这种方式,需要将图片按照类建文件夹并且放进去\n",
    "#如\n",
    "# root/dog/xxx.png\n",
    "# root/dog/xxy.png\n",
    "# root/dog/xxz.png\n",
    "\n",
    "# root/cat/123.png\n",
    "# root/cat/nsdf3.png\n",
    "# root/cat/asd932_.png\n",
    "data_transfrom = transforms.Compose([  # 对读取的图片进行以下指定操作\n",
    "    transforms.Resize((32, 32)),     # 图片放缩为 (300, 300), 统一处理的图像最好设置为统一的大小,这样之后的处理也更加方便\n",
    "    transforms.ToTensor(),             # 向量化,向量化时 每个点的像素值会除以255,整个向量中的元素值都在0-1之间      \n",
    "])\n",
    " \n",
    "img = datasets.ImageFolder('D:/书籍资料整理/kaggle/cifar-10/train', transform=data_transfrom)  # 指明读取的文件夹和读取方式,注意指明的是到文件夹的路径,不是到图片的路径\n",
    " \n",
    "imgLoader = torch.utils.data.DataLoader(img, batch_size=2, shuffle=False, num_workers=1)  # 指定读取配置信息\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
