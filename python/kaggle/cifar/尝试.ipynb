{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26908baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatrain: 49000\n",
      "49000 49000\n",
      "datatest: 1000\n",
      "labelstest: 1000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet34\n",
    "import time\n",
    "\n",
    "#Dataset 封装了__getitem__和__len__也是不可直接迭代的,需要使用\n",
    "#DataLoader 迭代\n",
    "class CIFAR10TrainDataset(Dataset):\n",
    "    def __init__(self, file_path=[], crop_size_img=None, crop_size_label=None):\n",
    "        \"\"\"para:\n",
    "            file_path(list): 数据和标签路径,列表元素第一个为图片路径，第二个为标签路径\n",
    "        \"\"\"\n",
    "        # 1 正确读入图片和标签路径\n",
    "        if len(file_path) != 2:\n",
    "            raise ValueError(\"同时需要图片和标签文件夹的路径，图片路径在前\")\n",
    "        self.img_path = file_path[0]\n",
    "        self.label_path = file_path[1]\n",
    "        # 2 从路径中取出图片和标签数据的文件名保持到两个列表当中（程序中的数据来源）\n",
    "        self.imgs = self.read_file(self.img_path)\n",
    "        labels=pd.read_csv(file_path[1])\n",
    "        self.labels = labels['y'].to_list()[:49000]\n",
    "#         print(\"labelstrain:\",len(self.labels))\n",
    "#         print(len(self.imgs),len(self.labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从文件名中读取数据（图片和标签都是png格式的图像数据）\n",
    "        img = self.imgs[index]\n",
    "        img = Image.open(img)\n",
    "        label = self.labels[index]\n",
    "        img = self.img_transform(img, label)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def read_file(self, path):\n",
    "        \"\"\"从文件夹中读取数据\"\"\"\n",
    "        files_list = os.listdir(path)\n",
    "        files_list = [x for x in files_list if int(re.search(r'(?<=train\\\\)[0-9]+',os.path.join(path, x)).group(0))<=49000]\n",
    "#         print(\"datatrain:\",len(files_list))\n",
    "        file_path_list = {int(re.search(r'(?<=train\\\\)[0-9]+',os.path.join(path, img)).group(0))-1:os.path.join(path, img) for img in files_list}\n",
    "        return file_path_list\n",
    "\n",
    "    def img_transform(self, img, label):\n",
    "        \"\"\"对图片和标签做一些数值处理\"\"\"\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "        img = transform(img)\n",
    "\n",
    "        return img\n",
    "    \n",
    "\n",
    "class CIFAR10TestDataset(Dataset):\n",
    "    def __init__(self, file_path=[], crop_size_img=None, crop_size_label=None):\n",
    "        \"\"\"para:\n",
    "            file_path(list): 数据和标签路径,列表元素第一个为图片路径，第二个为标签路径\n",
    "        \"\"\"\n",
    "        # 1 正确读入图片和标签路径\n",
    "        if len(file_path) != 2:\n",
    "            raise ValueError(\"同时需要图片和标签文件夹的路径，图片路径在前\")\n",
    "        self.img_path = file_path[0]\n",
    "        self.label_path = file_path[1]\n",
    "        # 2 从路径中取出图片和标签数据的文件名保持到两个列表当中（程序中的数据来源）\n",
    "        self.imgs = self.read_file(self.img_path)\n",
    "        labels=pd.read_csv(file_path[1])\n",
    "        self.labels = labels['y'].to_list()[49000:]     \n",
    "#         print(\"labelstest:\",len(self.labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从文件名中读取数据（图片和标签都是png格式的图像数据）\n",
    "        img = self.imgs[index]\n",
    "        img = Image.open(img)\n",
    "        label = self.labels[index]\n",
    "        img = self.img_transform(img, label)\n",
    "        \n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def read_file(self, path):\n",
    "        \"\"\"从文件夹中读取数据\"\"\"\n",
    "        files_list = os.listdir(path)\n",
    "        files_list = [x for x in files_list if int(re.search(r'(?<=train\\\\)[0-9]+',os.path.join(path, x)).group(0))>49000]\n",
    "#         print(\"datatest:\",len(files_list))\n",
    "        file_path_list = {int(re.search(r'(?<=train\\\\)[0-9]+',os.path.join(path, img)).group(0))-49001:os.path.join(path, img) for img in files_list}\n",
    "        return file_path_list\n",
    "\n",
    "    def img_transform(self, img, label):\n",
    "        \"\"\"对图片和标签做一些数值处理\"\"\"\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "        img = transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "dataset_train = CIFAR10TrainDataset([r'D:\\书籍资料整理\\kaggle\\cifar-10\\train',r'D:\\书籍资料整理\\kaggle\\cifar-10\\label.csv'])\n",
    "dataset_test = CIFAR10TestDataset([r'D:\\书籍资料整理\\kaggle\\cifar-10\\train',r'D:\\书籍资料整理\\kaggle\\cifar-10\\label.csv'])\n",
    "dataloader_train = DataLoader(dataset_train,   # 封装的对象\n",
    "                               batch_size=256,     # 输出的batchsize\n",
    "                               shuffle=True,     # 随机输出\n",
    "                               num_workers=3)    # 只有1个进程\n",
    "dataloader_test = DataLoader(dataset_test,   # 封装的对象\n",
    "                               batch_size=1,     # 输出的batchsize\n",
    "                               shuffle=False,     \n",
    "                               num_workers=3)    # 只有1个进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b1a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000\n"
     ]
    }
   ],
   "source": [
    "# for data in dataloader_train:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bd2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in dataloader_test:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "class Accumulator:  # @save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):  # @save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c441c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    #定义优化器\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    #定义损失函数\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_batches = len(train_iter)\n",
    "    #迭代\n",
    "    for epoch in range(num_epochs):\n",
    "        # [训练损失之和，训练准确率之和，样本数]\n",
    "        metric = Accumulator(3)\n",
    "        # 在训练之前必加的,\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet50(pretrained=False) #使用resnet50模型[残差网络] 不进行预训练\n",
    "device=try_gpu()\n",
    "train(net,dataloader_train,dataloader_test,30,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cd822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be02b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0793ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False) #使用resnet50模型[残差网络] 不进行预训练\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# 开始训练\n",
    "device=try_gpu()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time() #记录当前时间\n",
    "    for i, data in enumerate(dataloader_train):\n",
    "        # data里面包含图像数据（inputs）(tensor类型的）和标签（labels）(tensor类型）。\n",
    "        inputs, labels = data\n",
    "        # 将数据加载到相应设备中\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空上一轮梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "    print('epoch{} loss:{:.4f} time:{:.4f}'.format(epoch+1, loss.item(), time.time()-start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存训练模型,下次可以直接加载\n",
    "file_name = r'D:\\书籍资料整理\\kaggle\\cifar-10\\cifar10_resnet.pt'\n",
    "torch.save(model, file_name)\n",
    "print(file_name+' saved successfully!')\n",
    "\n",
    "# 测试\n",
    "model = torch.load(r'D:\\书籍资料整理\\kaggle\\cifar-10\\cifar10_resnet.pt') #加载模型\n",
    "model.eval() #切换到测试模式\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
